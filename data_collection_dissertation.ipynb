{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7+TJElCJFZCglIDXDeRUg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jessicashenone/dissertation/blob/main/data_collection_dissertation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data collection"
      ],
      "metadata": {
        "id": "R3g7okz6gz6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate and access Google Cloud services\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "xntuzguthRs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import library\n",
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "import time"
      ],
      "metadata": {
        "id": "TlgEjKjQl7vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg-wY0UXgxfT",
        "outputId": "7d98186f-9dd9-47dc-ccad-7a3006691df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getting video from PLNqKTn4CuEXdj7dkGKSkAJgkutERtXsi9 ...\n",
            " 16 video collected\n",
            "video prosessing: bfLEcKIHziQ\n",
            "title:I Am the Pressure | LeBron | Nike\n",
            " 96 collected\n",
            "video prosessing: o2w7vmyYeYk\n",
            "title:WINNING ISN'T FOR EVERYONE | NO RETREAT | BEBE VIO | NIKE\n",
            " 15 collected\n",
            "video prosessing: SxqIA6Une8M\n",
            "title:WINNING ISN'T FOR EVERYONE | CHARLES-ANTOINE KOUAKOU | NIKE\n",
            " 7 collected\n",
            "video prosessing: UR9zWdWvRXI\n",
            "title:WINNING ISN'T FOR EVERYONE | WINNING IS WINNING | NIKE\n",
            " 20 collected\n",
            "video prosessing: kBTOqjSToAg\n",
            "title:That's eight straight @ olympics gold medals for @ TeamUSA Women’s Basketball. # Paris2024\n",
            " 69 collected\n",
            "video prosessing: cT81z22tfss\n",
            "title:The reign of Team USA Men's Basketball continues at the Olympics. #Paris2024\n",
            " 13 collected\n",
            "video prosessing: ylco2-nUSeM\n",
            "title:WINNING ISN’T FOR EVERYONE | REGRETS | LEBRON\n",
            " 52 collected\n",
            "video prosessing: E0Yje6PBmEw\n",
            "title:WINNING ISN’T FOR EVERYONE | KIMIYA ALIZADEH\n",
            " 39 collected\n",
            "video prosessing: yP0grL4HZ1E\n",
            "title:WINNING ISN’T FOR EVERYONE | KEVIN DURANT | NIKE\n",
            " 57 collected\n",
            "video prosessing: 6UJ8VqS5O6o\n",
            "title:You miss 100% of the shots you don’t take. But against Wemby, you’ll be lucky if you get to take any\n",
            " 9 collected\n",
            "video prosessing: AGGojMioTgY\n",
            "title:WINNING ISN’T FOR EVERYONE | WINNER | CINDY NGAMBA\n",
            " 13 collected\n",
            "video prosessing: _Ra6wkIoJp0\n",
            "title:WINNING ISN’T FOR EVERYONE | AGAIN | LEBRON JAMES | NIKE\n",
            " 136 collected\n",
            "video prosessing: 60VUmjxuDLY\n",
            "title:WINNING ISN’T FOR EVERYONE | FACE | QINWEN ZHENG\n",
            " 96 collected\n",
            "video prosessing: avJzRKwdFwo\n",
            "title:WINNING ISN’T FOR EVERYONE | DO MORE | GIANNIS ANTETOKOUNMPO | NIKE\n",
            " 13 collected\n",
            "video prosessing: pwLergHG81c\n",
            "title:WINNING ISN’T FOR EVERYONE | AM I A BAD PERSON? | NIKE\n",
            " 1924 collected\n",
            "video prosessing: RTHSw0bJjdU\n",
            "title:WINNING ISN’T FOR EVERYONE | KOBE BRYANT | NIKE\n",
            " 70 collected\n"
          ]
        }
      ],
      "source": [
        "\n",
        "API_KEY = \"AIzaSyClZ4soA0RfkLil4MV5dFog6Ya08R_MQJY\"\n",
        "PLAYLIST_ID = \"PLNqKTn4CuEXdj7dkGKSkAJgkutERtXsi9\"\n",
        "\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "\n",
        "#get video id\n",
        "def get_video_ids_from_playlist(playlist_id):\n",
        "    video_ids = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.playlistItems().list(\n",
        "            part=\"contentDetails\",\n",
        "            playlistId=playlist_id,\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            video_ids.append(item[\"contentDetails\"][\"videoId\"])\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return video_ids\n",
        "\n",
        "#get video title\n",
        "def get_video_title(video_id):\n",
        "    try:\n",
        "        response = youtube.videos().list(\n",
        "            part=\"snippet\",\n",
        "            id=video_id\n",
        "        ).execute()\n",
        "        return response[\"items\"][0][\"snippet\"][\"title\"]\n",
        "    except:\n",
        "        return \"unknown title\"\n",
        "\n",
        "# get top comment\n",
        "def get_top_level_comments(video_id, video_title):\n",
        "    comments = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            maxResults=100,\n",
        "            pageToken=next_page_token,\n",
        "            textFormat=\"plainText\"\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
        "            comments.append({\n",
        "                \"video_id\": video_id,\n",
        "                \"video_title\": video_title,\n",
        "                \"comment\": snippet.get(\"textOriginal\", \"\"),\n",
        "                \"like_count\": snippet.get(\"likeCount\", 0),\n",
        "                \"published_at\": snippet.get(\"publishedAt\", \"\")\n",
        "            })\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return comments\n",
        "\n",
        "#visual process\n",
        "print(f\"getting video from {PLAYLIST_ID} ...\")\n",
        "video_ids = get_video_ids_from_playlist(PLAYLIST_ID)\n",
        "print(f\" {len(video_ids)} video collected\")\n",
        "\n",
        "all_comments = []\n",
        "\n",
        "for vid in video_ids:\n",
        "    print(f\"video prosessing: {vid}\")\n",
        "    title = get_video_title(vid)\n",
        "    print(f\"title:{title}\")\n",
        "    try:\n",
        "        comments = get_top_level_comments(vid, title)\n",
        "        all_comments.extend(comments)\n",
        "        print(f\" {len(comments)} collected\")\n",
        "        time.sleep(0.5)\n",
        "    except Exception as e:\n",
        "        print(f\"fail collectting {e}\")\n",
        "\n",
        "# save as\n",
        "df = pd.DataFrame(all_comments)\n",
        "df.to_csv(\"playlist_video_comments.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"playlist_video_comments.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PbEdY-HkmD7y",
        "outputId": "c3ca73e0-3f15-4b86-d9fe-029e70c454de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a18f5aa6-2ff5-413f-9f6b-333e5d139d54\", \"playlist_video_comments.csv\", 404319)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nike 2"
      ],
      "metadata": {
        "id": "FE-9iRlcm6cy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3766236b-dafd-44a1-b2a5-a4360f616e25",
        "id": "AL-UnBDFm3nM"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getting video from PLNqKTn4CuEXfhLY0nhUlOumNK2sV_Pe5e ...\n",
            " 4 video collected\n",
            "video prosessing: Cur3b5NX_nk\n",
            "title:Stairs | Nike\n",
            " 145 collected\n",
            "video prosessing: JfK0mHEy0po\n",
            "title:Joy | Nike\n",
            " 56 collected\n",
            "video prosessing: qvFnf2EEd20\n",
            "title:Sunshine | Nike\n",
            " 102 collected\n",
            "video prosessing: 17aYq81IENc\n",
            "title:Morning | Nike\n",
            " 109 collected\n"
          ]
        }
      ],
      "source": [
        "\n",
        "API_KEY = \"AIzaSyClZ4soA0RfkLil4MV5dFog6Ya08R_MQJY\"\n",
        "PLAYLIST_ID = \"PLNqKTn4CuEXfhLY0nhUlOumNK2sV_Pe5e\"\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "\n",
        "#get video id\n",
        "def get_video_ids_from_playlist(playlist_id):\n",
        "    video_ids = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.playlistItems().list(\n",
        "            part=\"contentDetails\",\n",
        "            playlistId=playlist_id,\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            video_ids.append(item[\"contentDetails\"][\"videoId\"])\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return video_ids\n",
        "\n",
        "#get video title\n",
        "def get_video_title(video_id):\n",
        "    try:\n",
        "        response = youtube.videos().list(\n",
        "            part=\"snippet\",\n",
        "            id=video_id\n",
        "        ).execute()\n",
        "        return response[\"items\"][0][\"snippet\"][\"title\"]\n",
        "    except:\n",
        "        return \"unknown title\"\n",
        "\n",
        "# get top comment\n",
        "def get_top_level_comments(video_id, video_title):\n",
        "    comments = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            maxResults=100,\n",
        "            pageToken=next_page_token,\n",
        "            textFormat=\"plainText\"\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
        "            comments.append({\n",
        "                \"video_id\": video_id,\n",
        "                \"video_title\": video_title,\n",
        "                \"comment\": snippet.get(\"textOriginal\", \"\"),\n",
        "                \"like_count\": snippet.get(\"likeCount\", 0),\n",
        "                \"published_at\": snippet.get(\"publishedAt\", \"\")\n",
        "            })\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return comments\n",
        "\n",
        "#visual process\n",
        "print(f\"getting video from {PLAYLIST_ID} ...\")\n",
        "video_ids = get_video_ids_from_playlist(PLAYLIST_ID)\n",
        "print(f\" {len(video_ids)} video collected\")\n",
        "\n",
        "all_comments = []\n",
        "\n",
        "for vid in video_ids:\n",
        "    print(f\"video prosessing: {vid}\")\n",
        "    title = get_video_title(vid)\n",
        "    print(f\"title:{title}\")\n",
        "    try:\n",
        "        comments = get_top_level_comments(vid, title)\n",
        "        all_comments.extend(comments)\n",
        "        print(f\" {len(comments)} collected\")\n",
        "        time.sleep(0.5)\n",
        "    except Exception as e:\n",
        "        print(f\"fail collectting {e}\")\n",
        "\n",
        "#save as\n",
        "df = pd.DataFrame(all_comments)\n",
        "df.to_csv(\"playlist_nike2_comments.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"playlist_nike2_comments.csv\")"
      ],
      "metadata": {
        "id": "pjPvaoltnOmL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ce4487c9-6c83-4b7e-d02e-1c6a9dddfeea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0c58da58-d91a-46e6-9178-1a412bbfef5b\", \"playlist_nike2_comments.csv\", 41636)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nike 3"
      ],
      "metadata": {
        "id": "50wz6939KtIm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc805634-bc1c-48b5-e50b-a5799eba67b6",
        "collapsed": true,
        "id": "dnDrpB7Tll-J"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getting video from PLNqKTn4CuEXdohOmnd32Dhpjtq8YVBMKJ ...\n",
            " 25 video collected\n",
            "video prosessing: 6f6NOsAs_BU\n",
            "title:The harder the hustle, the longer the receipt. Mal Swanson did that. #Nike\n",
            " 3 collected\n",
            "video prosessing: M8GrA3___KI\n",
            "title:Losing isn’t Juju Watkins' aesthetic.\n",
            " 18 collected\n",
            "video prosessing: OoVA_KGuaGw\n",
            "title:Talk is cheap but the work is expensive. #Nike\n",
            " 5 collected\n",
            "video prosessing: ors8hnDKYog\n",
            "title:Sweet smile, savage game. That's Sophia Wilson. #Nike\n",
            " 0 collected\n",
            "video prosessing: _on_Qbbqz3Q\n",
            "title:And Sophia Wilson's receipt is only getting longer. #Nike\n",
            " 3 collected\n",
            "video prosessing: LoQ3dbf1GpI\n",
            "title:When you're Sophia Wilson, you can never have too many goals. #Nike\n",
            " 2 collected\n",
            "video prosessing: OcT2mpQ1VwU\n",
            "title:Alexia Putellas did what she needed to do to make the team, then made it her own. #Nike\n",
            " 6 collected\n",
            "video prosessing: T9d8Gt1lqJA\n",
            "title:Alexia Putellas is winning so much, it’s hard to keep track. #Nike\n",
            " 3 collected\n",
            "video prosessing: quGBqozJd6s\n",
            "title:Queens don’t ask for permission. Nobody rules the pitch like Alexia Putellas. #Nike\n",
            " 9 collected\n",
            "video prosessing: tGVOFkPQxi0\n",
            "title:Catch her everywhere…if you can. Paige Bueckers is here to make a statement. #Nike\n",
            " 14 collected\n",
            "video prosessing: -78WBnpqJUw\n",
            "title:Too official to ever need validating but we printed Doechii’s receipt to remind you anyway. #nike\n",
            " 11 collected\n",
            "video prosessing: tty9HrxNKm0\n",
            "title:Sha’Carri Richardson knows her place. It’s first. #Nike\n",
            " 8 collected\n",
            "video prosessing: YBBczyhCc5g\n",
            "title:Jordan Chiles got that first win and isn't stepping off the podium any time soon. #Nike\n",
            " 1 collected\n",
            "video prosessing: FBdzfKG4_N8\n",
            "title:Never Routine. #Nike\n",
            " 5 collected\n",
            "video prosessing: qQ7SPeNyoH4\n",
            "title:You’re already late to the future. #Nike\n",
            " 12 collected\n",
            "video prosessing: jZHIfkQ9En8\n",
            "title:We know Caitlin Clark's game but some facts may surprise you... #Nike\n",
            " 15 collected\n",
            "video prosessing: xJE672K5DL4\n",
            "title:It's not where you're from. It's where you shoot from. #Nike\n",
            " 9 collected\n",
            "video prosessing: kV7RTymCeIE\n",
            "title:Every step, every rep. The proof is in the results for Sabrina Ionescu. #Nike\n",
            " 4 collected\n",
            "video prosessing: Hvm4bHrkcZY\n",
            "title:Run up the total. Sabrina Ionescu can cover #Nike\n",
            " 0 collected\n",
            "video prosessing: Z8-PsVHRAjY\n",
            "title:You Heard Right. Sabrina Ionescu doesn’t play games. She ends them. #Nike\n",
            " 4 collected\n",
            "video prosessing: MRrQPpSbKdE\n",
            "title:A’ja Wilson earned every line of this receipt. #Nike\n",
            " 4 collected\n",
            "video prosessing: dWD27K8hclo\n",
            "title:Results speak louder than critics. A’ja Wilson doesn’t have to brag. The stats do it for her. #Nike\n",
            " 13 collected\n",
            "video prosessing: difApTTQYqE\n",
            "title:Jordan Chiles is built different. Receipt included.\n",
            " 13 collected\n",
            "video prosessing: sG1dJJh5sHg\n",
            "title:For Sha'Carri Richardson, the hustle never stops. Neither does the receipt. #Nike\n",
            " 1 collected\n",
            "video prosessing: b0Ezn5pZE7o\n",
            "title:So Win. | Nike\n",
            " 971 collected\n"
          ]
        }
      ],
      "source": [
        "API_KEY = \"AIzaSyClZ4soA0RfkLil4MV5dFog6Ya08R_MQJY\"\n",
        "PLAYLIST_ID = \"PLNqKTn4CuEXdohOmnd32Dhpjtq8YVBMKJ\"\n",
        "\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "\n",
        "#get video id\n",
        "def get_video_ids_from_playlist(playlist_id):\n",
        "    video_ids = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.playlistItems().list(\n",
        "            part=\"contentDetails\",\n",
        "            playlistId=playlist_id,\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            video_ids.append(item[\"contentDetails\"][\"videoId\"])\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return video_ids\n",
        "\n",
        "#get video title\n",
        "def get_video_title(video_id):\n",
        "    try:\n",
        "        response = youtube.videos().list(\n",
        "            part=\"snippet\",\n",
        "            id=video_id\n",
        "        ).execute()\n",
        "        return response[\"items\"][0][\"snippet\"][\"title\"]\n",
        "    except:\n",
        "        return \"unknown title\"\n",
        "\n",
        "# get top comment\n",
        "def get_top_level_comments(video_id, video_title):\n",
        "    comments = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            maxResults=100,\n",
        "            pageToken=next_page_token,\n",
        "            textFormat=\"plainText\"\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
        "            comments.append({\n",
        "                \"video_id\": video_id,\n",
        "                \"video_title\": video_title,\n",
        "                \"comment\": snippet.get(\"textOriginal\", \"\"),\n",
        "                \"like_count\": snippet.get(\"likeCount\", 0),\n",
        "                \"published_at\": snippet.get(\"publishedAt\", \"\")\n",
        "            })\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return comments\n",
        "\n",
        "#visual process\n",
        "print(f\"getting video from {PLAYLIST_ID} ...\")\n",
        "video_ids = get_video_ids_from_playlist(PLAYLIST_ID)\n",
        "print(f\" {len(video_ids)} video collected\")\n",
        "\n",
        "all_comments = []\n",
        "\n",
        "for vid in video_ids:\n",
        "    print(f\"video prosessing: {vid}\")\n",
        "    title = get_video_title(vid)\n",
        "    print(f\"title:{title}\")\n",
        "    try:\n",
        "        comments = get_top_level_comments(vid, title)\n",
        "        all_comments.extend(comments)\n",
        "        print(f\" {len(comments)} collected\")\n",
        "        time.sleep(0.5)\n",
        "    except Exception as e:\n",
        "        print(f\"fail collectting {e}\")\n",
        "\n",
        "#save as\n",
        "df = pd.DataFrame(all_comments)\n",
        "df.to_csv(\"playlist_nike3_comments.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"playlist_nike3_comments.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4rMkSaTwlvx5",
        "outputId": "b4960969-68ae-4bd3-cd17-1eb2e92db275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_deb1af45-c148-4c52-aed3-75e241cfd1b2\", \"playlist_nike3_comments.csv\", 113319)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "API_KEY = \"AIzaSyClZ4soA0RfkLil4MV5dFog6Ya08R_MQJY\"\n",
        "VIDEO_ID = \"C_BZQkU5Cds\"\n",
        "\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "\n",
        "\n",
        "def get_video_title(video_id):\n",
        "    response = youtube.videos().list(\n",
        "        part=\"snippet\",\n",
        "        id=video_id\n",
        "    ).execute()\n",
        "    return response[\"items\"][0][\"snippet\"][\"title\"]\n",
        "\n",
        "\n",
        "def get_top_level_comments(video_id, video_title):\n",
        "    comments = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            maxResults=100,\n",
        "            pageToken=next_page_token,\n",
        "            textFormat=\"plainText\"\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
        "            comments.append({\n",
        "                \"video_id\": video_id,\n",
        "                \"video_title\": video_title,\n",
        "                \"comment\": snippet.get(\"textOriginal\", \"\"),\n",
        "                \"like_count\": snippet.get(\"likeCount\", 0),\n",
        "                \"published_at\": snippet.get(\"publishedAt\", \"\")\n",
        "            })\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return comments\n",
        "\n",
        "\n",
        "print(f\"video processing {VIDEO_ID}\")\n",
        "title = get_video_title(VIDEO_ID)\n",
        "print(f\"video title {title}\")\n",
        "\n",
        "comments = get_top_level_comments(VIDEO_ID, title)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(comments)\n",
        "df.to_csv(\"single_nike_comments.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0qwzWbQmroF",
        "outputId": "29976fe0-6494-490d-e656-e5be0204cfc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "video processing C_BZQkU5Cds\n",
            "video title WHAT IF YOU CAN? | Nike\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"single_nike_comments.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YkVemjct0oQ1",
        "outputId": "7488326b-19f0-4106-9949-68b7536a600b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4a553e7c-5b1f-4a6b-b535-96d4173880f5\", \"single_nike_comments.csv\", 50219)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "adidas"
      ],
      "metadata": {
        "id": "i7UZxNG6LqJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "API_KEY = \"AIzaSyClZ4soA0RfkLil4MV5dFog6Ya08R_MQJY\"\n",
        "PLAYLIST_ID = \"PLM-bRdh5zDg_uaXW3HgTBtDWb2db5PeRa\"\n",
        "\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "\n",
        "#get video id\n",
        "def get_video_ids_from_playlist(playlist_id):\n",
        "    video_ids = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.playlistItems().list(\n",
        "            part=\"contentDetails\",\n",
        "            playlistId=playlist_id,\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            video_ids.append(item[\"contentDetails\"][\"videoId\"])\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return video_ids\n",
        "\n",
        "#get video title\n",
        "def get_video_title(video_id):\n",
        "    try:\n",
        "        response = youtube.videos().list(\n",
        "            part=\"snippet\",\n",
        "            id=video_id\n",
        "        ).execute()\n",
        "        return response[\"items\"][0][\"snippet\"][\"title\"]\n",
        "    except:\n",
        "        return \"unknown title\"\n",
        "\n",
        "# get top comment\n",
        "def get_top_level_comments(video_id, video_title):\n",
        "    comments = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            maxResults=100,\n",
        "            pageToken=next_page_token,\n",
        "            textFormat=\"plainText\"\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
        "            comments.append({\n",
        "                \"video_id\": video_id,\n",
        "                \"video_title\": video_title,\n",
        "                \"comment\": snippet.get(\"textOriginal\", \"\"),\n",
        "                \"like_count\": snippet.get(\"likeCount\", 0),\n",
        "                \"published_at\": snippet.get(\"publishedAt\", \"\")\n",
        "            })\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return comments\n",
        "\n",
        "#visual process\n",
        "print(f\"getting video from {PLAYLIST_ID} ...\")\n",
        "video_ids = get_video_ids_from_playlist(PLAYLIST_ID)\n",
        "print(f\" {len(video_ids)} video collected\")\n",
        "\n",
        "all_comments = []\n",
        "\n",
        "for vid in video_ids:\n",
        "    print(f\"video prosessing: {vid}\")\n",
        "    title = get_video_title(vid)\n",
        "    print(f\"title:{title}\")\n",
        "    try:\n",
        "        comments = get_top_level_comments(vid, title)\n",
        "        all_comments.extend(comments)\n",
        "        print(f\" {len(comments)} collected\")\n",
        "        time.sleep(0.5)\n",
        "    except Exception as e:\n",
        "        print(f\"fail collectting {e}\")\n",
        "\n",
        "#save as\n",
        "df = pd.DataFrame(all_comments)\n",
        "df.to_csv(\"playlist_addidas_comments.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6fSSjqG1_0H",
        "outputId": "2ba2051a-0fef-42be-ea96-c053bf5b3b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getting video from PLM-bRdh5zDg_uaXW3HgTBtDWb2db5PeRa ...\n",
            " 17 video collected\n",
            "video prosessing: obeGm1RRPLg\n",
            "title:TRAILER Anthony Edwards by his best friend Nick Maddox\n",
            " 23 collected\n",
            "video prosessing: Al3h1DXwwRA\n",
            "title:We All Need Someone To Make Us Believe | adidas\n",
            " 547 collected\n",
            "video prosessing: UCWkNZ5Y8-E\n",
            "title:Anthony Edwards Takes On The 20 Foot Hoop | adidas\n",
            " 617 collected\n",
            "video prosessing: 9zLhexTM2s4\n",
            "title:Martinelli, Macario, Fishel and Pereira Take on The Football Triangle | adidas\n",
            " 44 collected\n",
            "video prosessing: a6382QsPros\n",
            "title:The Giant Tennis Court Challenge With Felix & Francisco | adidas\n",
            " 20 collected\n",
            "video prosessing: 6Ru_MuQ6VbQ\n",
            "title:unknown title\n",
            "fail collectting <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=6Ru_MuQ6VbQ&maxResults=100&textFormat=plainText&key=AIzaSyClZ4soA0RfkLil4MV5dFog6Ya08R_MQJY&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.', 'domain': 'youtube.commentThread', 'reason': 'videoNotFound', 'location': 'videoId', 'locationType': 'parameter'}]\">\n",
            "video prosessing: FzaS0V_FCrI\n",
            "title:You Got This | adidas\n",
            " 153 collected\n",
            "video prosessing: Flcl9lIr9VI\n",
            "title:Emiliano Martínez's Insight Into Penalty Shootouts | adidas\n",
            " 165 collected\n",
            "video prosessing: a071jZPWhaY\n",
            "title:Nneka Ogwumike's Insight Into Free Throws | Adidas\n",
            " 12 collected\n",
            "video prosessing: vxQYN_-DqB4\n",
            "title:Ludvig Åberg's Insights Into Putting | Adidas\n",
            " 7 collected\n",
            "video prosessing: lw-pwHC0gsE\n",
            "title:Rose Zhang's Insights Into Putting | adidas\n",
            " 5 collected\n",
            "video prosessing: 32__plJ-Q_Y\n",
            "title:Summer of Sport Anthem Film | adidas\n",
            " 65 collected\n",
            "video prosessing: lLLiNREyJ-E\n",
            "title:unknown title\n",
            "fail collectting <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=lLLiNREyJ-E&maxResults=100&textFormat=plainText&key=AIzaSyClZ4soA0RfkLil4MV5dFog6Ya08R_MQJY&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.', 'domain': 'youtube.commentThread', 'reason': 'videoNotFound', 'location': 'videoId', 'locationType': 'parameter'}]\">\n",
            "video prosessing: Y_GVqaZ0uvE\n",
            "title:Anthony Edwards, By His Best Friend Nick Maddox\n",
            " 355 collected\n",
            "video prosessing: v2pX0E5YZfk\n",
            "title:TRAILER | Aitana Bonmatí by her friend Maria Rodríguez\n",
            " 13 collected\n",
            "video prosessing: BT4bh4kXmBI\n",
            "title:unknown title\n",
            "fail collectting <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=BT4bh4kXmBI&maxResults=100&textFormat=plainText&key=AIzaSyClZ4soA0RfkLil4MV5dFog6Ya08R_MQJY&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.', 'domain': 'youtube.commentThread', 'reason': 'videoNotFound', 'location': 'videoId', 'locationType': 'parameter'}]\">\n",
            "video prosessing: GFT6Wt9VDWQ\n",
            "title:Great Rivals Make Great Motivation | adidas\n",
            " 39 collected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"playlist_addidas_comments.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "D_cZJCk-4VTA",
        "outputId": "6d6ce463-f945-4be7-f0b8-aed762649bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ee6dc804-f39f-43ae-a4c6-f982a78e42a9\", \"playlist_addidas_comments.csv\", 263755)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "puma"
      ],
      "metadata": {
        "id": "gbalOpEoL9Lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "API_KEY = \"AIzaSyClZ4soA0RfkLil4MV5dFog6Ya08R_MQJY\"\n",
        "PLAYLIST_ID = \"PLQqeBCtRiHitRiyLy-_RThdOyHM1ZyHcN\"\n",
        "\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "\n",
        "#get video id\n",
        "def get_video_ids_from_playlist(playlist_id):\n",
        "    video_ids = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.playlistItems().list(\n",
        "            part=\"contentDetails\",\n",
        "            playlistId=playlist_id,\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            video_ids.append(item[\"contentDetails\"][\"videoId\"])\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return video_ids\n",
        "\n",
        "#get video title\n",
        "def get_video_title(video_id):\n",
        "    try:\n",
        "        response = youtube.videos().list(\n",
        "            part=\"snippet\",\n",
        "            id=video_id\n",
        "        ).execute()\n",
        "        return response[\"items\"][0][\"snippet\"][\"title\"]\n",
        "    except:\n",
        "        return \"unknown title\"\n",
        "\n",
        "# get top comment\n",
        "def get_top_level_comments(video_id, video_title):\n",
        "    comments = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            maxResults=100,\n",
        "            pageToken=next_page_token,\n",
        "            textFormat=\"plainText\"\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
        "            comments.append({\n",
        "                \"video_id\": video_id,\n",
        "                \"video_title\": video_title,\n",
        "                \"comment\": snippet.get(\"textOriginal\", \"\"),\n",
        "                \"like_count\": snippet.get(\"likeCount\", 0),\n",
        "                \"published_at\": snippet.get(\"publishedAt\", \"\")\n",
        "            })\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return comments\n",
        "\n",
        "#visual process\n",
        "print(f\"getting video from {PLAYLIST_ID} ...\")\n",
        "video_ids = get_video_ids_from_playlist(PLAYLIST_ID)\n",
        "print(f\" {len(video_ids)} video collected\")\n",
        "\n",
        "all_comments = []\n",
        "\n",
        "for vid in video_ids:\n",
        "    print(f\"video prosessing: {vid}\")\n",
        "    title = get_video_title(vid)\n",
        "    print(f\"title:{title}\")\n",
        "    try:\n",
        "        comments = get_top_level_comments(vid, title)\n",
        "        all_comments.extend(comments)\n",
        "        print(f\" {len(comments)} collected\")\n",
        "        time.sleep(0.5)\n",
        "    except Exception as e:\n",
        "        print(f\"fail collectting {e}\")\n",
        "\n",
        "#save as\n",
        "df = pd.DataFrame(all_comments)\n",
        "df.to_csv(\"playlist_puma_comments.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgAmKj-1OL93",
        "outputId": "1b40b224-5f03-49e0-9d7a-d74733741ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getting video from PLQqeBCtRiHitRiyLy-_RThdOyHM1ZyHcN ...\n",
            " 9 video collected\n",
            "video prosessing: TRZKzXYXadU\n",
            "title:Behind the scenes of Go Wild\n",
            " 10 collected\n",
            "video prosessing: _OWG7NAGxyM\n",
            "title:The rush of beating your own PR. #GoWild\n",
            " 3 collected\n",
            "video prosessing: mLzhw1LhVOg\n",
            "title:Sometimes you’ve gotta squeeze in the laps during naps. #GoWild\n",
            " 2 collected\n",
            "video prosessing: df4ia6tPZoM\n",
            "title:Nothing stops a runner from pursuing the next high. #GoWild\n",
            " 19 collected\n",
            "video prosessing: DPpD1WbhBHw\n",
            "title:That text can wait. The runner’s high can’t. #GoWild\n",
            " 20 collected\n",
            "video prosessing: cd9hpP1djNQ\n",
            "title:No commute necessary when you ARE the commute. #GoWild\n",
            " 5 collected\n",
            "video prosessing: VXTJKJ0HvTQ\n",
            "title:Runner’s high – it’s a thing for a reason. #GoWild\n",
            " 29 collected\n",
            "video prosessing: LaI7Ty0UeRk\n",
            "title:PUMA. GO WILD.\n",
            " 1085 collected\n",
            "video prosessing: tgrWmJwdBPQ\n",
            "title:Enter: runner’s high. #GoWild\n",
            " 0 collected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"playlist_puma_comments.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NnG2TN1rOhYa",
        "outputId": "01cbba6c-1169-41cd-f6cb-3a5c0507a49a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_865a42f9-fc71-42c9-ad91-f863b0cbc1c2\", \"playlist_puma_comments.csv\", 132577)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reebox"
      ],
      "metadata": {
        "id": "c2BhCcGOMFtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"AIzaSyClZ4soA0RfkLil4MV5dFog6Ya08R_MQJY\"\n",
        "PLAYLIST_ID = \"PLpzkathSY1EdOOsdmjGGeTl4LL3vnMkr-\"\n",
        "\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "\n",
        "#get video id\n",
        "def get_video_ids_from_playlist(playlist_id):\n",
        "    video_ids = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.playlistItems().list(\n",
        "            part=\"contentDetails\",\n",
        "            playlistId=playlist_id,\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            video_ids.append(item[\"contentDetails\"][\"videoId\"])\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return video_ids\n",
        "\n",
        "#get video title\n",
        "def get_video_title(video_id):\n",
        "    try:\n",
        "        response = youtube.videos().list(\n",
        "            part=\"snippet\",\n",
        "            id=video_id\n",
        "        ).execute()\n",
        "        return response[\"items\"][0][\"snippet\"][\"title\"]\n",
        "    except:\n",
        "        return \"unknown title\"\n",
        "\n",
        "# get top comment\n",
        "def get_top_level_comments(video_id, video_title):\n",
        "    comments = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            maxResults=100,\n",
        "            pageToken=next_page_token,\n",
        "            textFormat=\"plainText\"\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
        "            comments.append({\n",
        "                \"video_id\": video_id,\n",
        "                \"video_title\": video_title,\n",
        "                \"comment\": snippet.get(\"textOriginal\", \"\"),\n",
        "                \"like_count\": snippet.get(\"likeCount\", 0),\n",
        "                \"published_at\": snippet.get(\"publishedAt\", \"\")\n",
        "            })\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return comments\n",
        "\n",
        "#visual process\n",
        "print(f\"getting video from {PLAYLIST_ID} ...\")\n",
        "video_ids = get_video_ids_from_playlist(PLAYLIST_ID)\n",
        "print(f\" {len(video_ids)} video collected\")\n",
        "\n",
        "all_comments = []\n",
        "\n",
        "for vid in video_ids:\n",
        "    print(f\"video prosessing: {vid}\")\n",
        "    title = get_video_title(vid)\n",
        "    print(f\"title:{title}\")\n",
        "    try:\n",
        "        comments = get_top_level_comments(vid, title)\n",
        "        all_comments.extend(comments)\n",
        "        print(f\" {len(comments)} collected\")\n",
        "        time.sleep(0.5)\n",
        "    except Exception as e:\n",
        "        print(f\"fail collectting {e}\")\n",
        "\n",
        "#save as\n",
        "df = pd.DataFrame(all_comments)\n",
        "df.to_csv(\"playlist_rb_comments.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "n4g7TRHIP_YP",
        "outputId": "d82abfe5-af86-4874-a258-a9451f2f9ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getting video from PLpzkathSY1EdOOsdmjGGeTl4LL3vnMkr- ...\n",
            " 11 video collected\n",
            "video prosessing: QGvoXDQaYnQ\n",
            "title:REEBOK | SPORT IS EVERYTHING | ANUEL AA\n",
            " 4 collected\n",
            "video prosessing: iImdsexc07c\n",
            "title:REEBOK | SPORT IS EVERYTHING | TOBE NWIGWE\n",
            " 2 collected\n",
            "video prosessing: v-TuVuLPfEs\n",
            "title:REEBOK | SPORT IS EVERYTHING | CHRISTIAN HARRIS\n",
            " 3 collected\n",
            "video prosessing: f462EuyiQYo\n",
            "title:REEBOK | SPORT IS EVERYTHING | ANGEL REESE\n",
            " 5 collected\n",
            "video prosessing: aMTzxjmwAxI\n",
            "title:REEBOK | SPORT IS EVERYTHING | BGIRL PAULINA & BREAKIN KIDS\n",
            " 4 collected\n",
            "video prosessing: Hmljwe14_0E\n",
            "title:REEBOK | SPORT IS EVERYTHING | LUIS MEJÍA\n",
            " 0 collected\n",
            "video prosessing: RvrLKTtKo0o\n",
            "title:REEBOK | SPORT IS EVERYTHING | JUSTIN FIELDS\n",
            " 1 collected\n",
            "video prosessing: BJqXvkydDmY\n",
            "title:REEBOK | SPORT IS EVERYTHING | SURYAKUMAR YADAV (SKY)\n",
            " 2 collected\n",
            "video prosessing: EWJcXIguSHQ\n",
            "title:REEBOK | SPORT IS EVERYTHING | SHAKUR STEVENSON\n",
            " 3 collected\n",
            "video prosessing: K6cTGCW3Y3c\n",
            "title:REEBOK | SPORT IS EVERYTHING | LYDIA OLDHAM\n",
            " 1 collected\n",
            "video prosessing: FQyYXhplQog\n",
            "title:REEBOK | SPORT IS EVERYTHING\n",
            " 18 collected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"playlist_rb_comments.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nw81YrYgQZIx",
        "outputId": "f8922a14-8eb4-42fa-9d7b-79dafc4a64e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0ce59dcb-27b3-4424-af96-86841189a5de\", \"playlist_rb_comments.csv\", 7607)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "under amoour"
      ],
      "metadata": {
        "id": "QVURvuPsNyqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "API_KEY = \"AIzaSyClZ4soA0RfkLil4MV5dFog6Ya08R_MQJY\"\n",
        "PLAYLIST_ID = \"PLC5tgvuNxfsKx2bkN9S6ktpRCB-BTUs3z\"\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "\n",
        "\n",
        "#get video id\n",
        "def get_video_ids_from_playlist(playlist_id):\n",
        "    video_ids = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.playlistItems().list(\n",
        "            part=\"contentDetails\",\n",
        "            playlistId=playlist_id,\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            video_ids.append(item[\"contentDetails\"][\"videoId\"])\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return video_ids\n",
        "\n",
        "#get video title\n",
        "def get_video_title(video_id):\n",
        "    try:\n",
        "        response = youtube.videos().list(\n",
        "            part=\"snippet\",\n",
        "            id=video_id\n",
        "        ).execute()\n",
        "        return response[\"items\"][0][\"snippet\"][\"title\"]\n",
        "    except:\n",
        "        return \"unknown title\"\n",
        "\n",
        "# get top comment\n",
        "def get_top_level_comments(video_id, video_title):\n",
        "    comments = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            maxResults=100,\n",
        "            pageToken=next_page_token,\n",
        "            textFormat=\"plainText\"\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
        "            comments.append({\n",
        "                \"video_id\": video_id,\n",
        "                \"video_title\": video_title,\n",
        "                \"comment\": snippet.get(\"textOriginal\", \"\"),\n",
        "                \"like_count\": snippet.get(\"likeCount\", 0),\n",
        "                \"published_at\": snippet.get(\"publishedAt\", \"\")\n",
        "            })\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return comments\n",
        "\n",
        "#visual process\n",
        "print(f\"getting video from {PLAYLIST_ID} ...\")\n",
        "video_ids = get_video_ids_from_playlist(PLAYLIST_ID)\n",
        "print(f\" {len(video_ids)} video collected\")\n",
        "\n",
        "all_comments = []\n",
        "\n",
        "for vid in video_ids:\n",
        "    print(f\"video prosessing: {vid}\")\n",
        "    title = get_video_title(vid)\n",
        "    print(f\"title:{title}\")\n",
        "    try:\n",
        "        comments = get_top_level_comments(vid, title)\n",
        "        all_comments.extend(comments)\n",
        "        print(f\" {len(comments)} collected\")\n",
        "        time.sleep(0.5)\n",
        "    except Exception as e:\n",
        "        print(f\"fail collectting {e}\")\n",
        "\n",
        "#save as\n",
        "df = pd.DataFrame(all_comments)\n",
        "df.to_csv(\"playlist_underaemour_comments.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "typBVh_tR_eO",
        "outputId": "646579d4-31b3-42c7-d7fd-da9a1d788186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getting video from PLC5tgvuNxfsKx2bkN9S6ktpRCB-BTUs3z ...\n",
            " 10 video collected\n",
            "video prosessing: T3O-LXZKxJo\n",
            "title:unknown title\n",
            "fail collectting <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=T3O-LXZKxJo&maxResults=100&textFormat=plainText&key=AIzaSyClZ4soA0RfkLil4MV5dFog6Ya08R_MQJY&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.', 'domain': 'youtube.commentThread', 'reason': 'videoNotFound', 'location': 'videoId', 'locationType': 'parameter'}]\">\n",
            "video prosessing: s3Lwtf1C7wE\n",
            "title:The Only Way Is Through: Kyle Dietz\n",
            " 6 collected\n",
            "video prosessing: 2zw6fXixWdc\n",
            "title:The Only Way Is Through: Imke Salander\n",
            " 45 collected\n",
            "video prosessing: jLDh-dbosRE\n",
            "title:The Only Way Is Through: Cynthia Lozada\n",
            " 3 collected\n",
            "video prosessing: c-pAFTPFY_g\n",
            "title:The Only Way Is Through: Jin Yuan\n",
            " 2 collected\n",
            "video prosessing: 1MZtPGXkM4g\n",
            "title:The Only Way is Through: Cam Newton\n",
            " 12 collected\n",
            "video prosessing: opgaSxAwBiM\n",
            "title:The Only Way Is Through | Train Your Mind. Train Your Game\n",
            " 12 collected\n",
            "video prosessing: OILO4LGlLfA\n",
            "title:The Only Way Is Through | Train Your Mind. Train Your Game\n",
            " 1 collected\n",
            "video prosessing: yabErIWrtVs\n",
            "title:The Only Way Is Through | Train Your Mind. Train Your Game.\n",
            " 1 collected\n",
            "video prosessing: KGJvYI9NaMo\n",
            "title:The Only Way Is Through | Push Past The Cold. Keep Your Momentum.\n",
            " 9 collected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"AIzaSyClZ4soA0RfkLil4MV5dFog6Ya08R_MQJY\"\n",
        "VIDEO_ID = \"2zw6fXixWdc\"\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "\n",
        "# get title\n",
        "def get_video_title(video_id):\n",
        "    response = youtube.videos().list(\n",
        "        part=\"snippet\",\n",
        "        id=video_id\n",
        "    ).execute()\n",
        "    return response[\"items\"][0][\"snippet\"][\"title\"]\n",
        "\n",
        "# get top level comments\n",
        "def get_top_level_comments(video_id, video_title):\n",
        "    comments = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            maxResults=100,\n",
        "            pageToken=next_page_token,\n",
        "            textFormat=\"plainText\"\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
        "            comments.append({\n",
        "                \"video_id\": video_id,\n",
        "                \"video_title\": video_title,\n",
        "                \"comment\": snippet.get(\"textOriginal\", \"\"),\n",
        "                \"like_count\": snippet.get(\"likeCount\", 0),\n",
        "                \"published_at\": snippet.get(\"publishedAt\", \"\")\n",
        "            })\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return comments\n",
        "\n",
        "print(f\"video totle:{VIDEO_ID}\")\n",
        "title = get_video_title(VIDEO_ID)\n",
        "print(f\"videotitle:{title}\")\n",
        "\n",
        "comments = get_top_level_comments(VIDEO_ID, title)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(comments)\n",
        "df.to_csv(\"single_ua2_comments.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHhSdOGwUmbq",
        "outputId": "b22961bb-fce9-4352-e312-b352f63c6e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "video totle:2zw6fXixWdc\n",
            "videotitle:The Only Way Is Through: Imke Salander\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"single_ua2_comments.csv\")\n",
        "files.download(\"playlist_underaemour_comments.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wQP0EIA3V2Qk",
        "outputId": "e3bea571-9745-461e-8d65-7f7e8bed2f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a86636de-2322-4521-bfea-88af0ee4360b\", \"single_ua2_comments.csv\", 7174)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9314aa30-607d-4737-849f-7acfe0e07c9f\", \"playlist_underaemour_comments.csv\", 14283)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I3FF5TpIWMTk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}